{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fd32e9",
   "metadata": {},
   "source": [
    "# PROBLEM 1 – Reading the data (5 pts)\n",
    "• Read in file \"train.tsv\" from the Stanford Sentiment Treebank (SST) as shared in the GLUE task.\n",
    "(See section \"DATA\" above.)\n",
    "• Next, split your dataset into train, test, and validation datasets with these sizes (Note that 100\n",
    "is a small size for test and validation datasets; it was selected to simplify this homework):\n",
    "o Validation: 100 rows\n",
    "o Test: 100 rows\n",
    "o Training: All remaining rows.\n",
    "• Review the column \"label\" which indicates positive=1 or negative=0 sentiment. What is the prior\n",
    "probability of each class on your training set? Show results in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca313f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/pradaapss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0       hide new secretions from the parental units       0\n",
       "1               contains no wit , only labored gags       0\n",
       "2  that loves its characters and communicates som...      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Read in the SST dataset\n",
    "sst_df = pd.read_csv('/Users/pradaapss/Desktop/Semester 3/CS 585 NLP/Assignment 3/SST-2/train.tsv', sep='\\t', usecols=['sentence', 'label'])\n",
    "\n",
    "sst_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bad67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probability of Positive Class: 0.5578936395180867\n",
      "Prior Probability of Negative Class: 0.4421063604819134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"train_df, test_df = train_test_split(sst_df, test_size=100, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=100, random_state=42)\"\"\"\n",
    "\n",
    "val_df = sst_df.sample(n=100, random_state=1)\n",
    "test_df = sst_df.sample(n=100, random_state=2)\n",
    "train_df = sst_df.drop(val_df.index).drop(test_df.index)\n",
    "\n",
    "# Calculate the prior probabilities of each class in the training set\n",
    "positive_count = (train_df['label'] == 1).sum()\n",
    "negative_count = (train_df['label'] == 0).sum()\n",
    "\n",
    "total_count = len(train_df)\n",
    "\n",
    "# Calculate the prior probabilities of the positive and negative classes\n",
    "prior_prob_positive = positive_count / total_count\n",
    "prior_prob_negative = negative_count / total_count\n",
    "\n",
    "print(\"Prior Probability of Positive Class:\", prior_prob_positive)\n",
    "print(\"Prior Probability of Negative Class:\", prior_prob_negative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c5e87",
   "metadata": {},
   "source": [
    "# PROBLEM 2 – Tokenizing data (10 pts)\n",
    "• Write a function that takes a sentence as input, represented as a string, and converts it to a\n",
    "tokenized sequence padded by start and end symbols. For example, \"hello class\" would be\n",
    "converted to:\n",
    "    o ['<s>', 'hello', 'class', '</s>']\n",
    "• Apply your function to all sentences in your training set. Show the tokenization of the first\n",
    "sentence of your training set in your notebook output.\n",
    "• What is the vocabulary size of your training set? Include your start and end symbol in your\n",
    "vocabulary. Show your result in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c534b3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization of the first sentence:  ['<s>', 'hide', 'new', 'secretions', 'from', 'the', 'parental', 'units', '</s>']\n",
      "Vocabulary Size: 14815\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sentence):\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    tokens = ['<s>'] + tokens + ['</s>']\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenize function to each sentence in the 'sentence' column of the DataFrame\n",
    "train_df['tokenized_sentences'] = train_df['sentence'].apply(tokenize)\n",
    "\n",
    "print(\"Tokenization of the first sentence: \", train_df['tokenized_sentences'].iloc[0])\n",
    "\n",
    "vocabulary = set()\n",
    "\n",
    "# Iterate through each tokenized sentence in the 'tokenized_sentences' column\n",
    "for sentence in train_df['tokenized_sentences']:\n",
    "    vocabulary.update(sentence)\n",
    "\n",
    "# Calculate the size of the vocabulary\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(f\"Vocabulary Size: {vocabulary_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f48cf5",
   "metadata": {},
   "source": [
    "# PROBLEM 3 – Bigram counts (10 pts)\n",
    "• Write a function that takes an array of tokenized sequences as input (i.e., a list of lists) and\n",
    "counts bigram frequencies in that dataset. Your function should return a two-level dictionary\n",
    "(dictionary of dictionaries) or similar data structure, where the value at index [wi][wj] gives the\n",
    "frequency count of bigram (wi, wj). For example, this expression would give the counts of the\n",
    "bigram \"academy award\":\n",
    "bigram_counts[\"academy\"][\"award\"]\n",
    "• Apply your function to the output of problem 2. You should build one counter that represents all\n",
    "sentences in the training dataset.\n",
    "• Use this result to show how many times a sentence starts with \"the\". That is, how often do you\n",
    "see the bigram (\"<s>\",\"the\") in your training set? Show results in your notebook.\n",
    "    \n",
    "PROGRAMMING HINTS:\n",
    "• You can use the function nltk.bigrams to convert a sequence to bigrams, but you are not\n",
    "required to do so.\n",
    "• In python, you can use function \"dict.get(key, default)\" to return the value \"default\" if \"key\" is\n",
    "not present in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad2304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times a sentence starts with 'the' in the training set: 4456\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_bigrams(tokenized_sequences):\n",
    "    bigram_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for sequence in tokenized_sequences:\n",
    "        for i in range(len(sequence) - 1):\n",
    "            wi, wj = sequence[i], sequence[i + 1]\n",
    "            bigram_counts[wi][wj] += 1\n",
    "\n",
    "    return bigram_counts\n",
    "\n",
    "# Apply the function to the tokenized sequences in the training set\n",
    "bigram_counts = count_bigrams(train_df['tokenized_sentences'])\n",
    "\n",
    "# Show how many times a sentence starts with \"the\" (\"<s>\", \"the\")\n",
    "the_start_count = bigram_counts[\"<s>\"][\"the\"]\n",
    "print(\"Number of times a sentence starts with 'the' in the training set:\", the_start_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f872d12",
   "metadata": {},
   "source": [
    "# PROBLEM 4 – Smoothing (20 pts)\n",
    "• Write a function that implements formula [6.13] in that E-NLP textbook (page 129, 6.2\n",
    "Smoothing and discounting). That is, write a function that applies smoothing and returns a\n",
    "(negative) log-probability of a word given the previous word in the sequence. It is suggested\n",
    "that you use these parameters:\n",
    "    o The current word, wm\n",
    "    o The previous word, wm-1\n",
    "    o bigram counts (output of Problem 3)\n",
    "    o alpha, a smoothing parameter\n",
    "    o vocabulary size\n",
    "• Using this function to show the log probability that the word \"academy\" will be followed by the\n",
    "word \"award\". Try this with alpha=0.001 and alpha=0.5 (you should see very different results!).\n",
    "Show your results in your notebook.\n",
    "PROGRAMMING ALTERNATIVE: If you are familiar with python classes, you may build a LanguageModel\n",
    "class that is initialized with the above parameters and implements formula [6.13] as a member function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47fabdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of 'academy' followed by 'award' with alpha=0.001: -1.025138261286736\n",
      "Log probability of 'academy' followed by 'award' with alpha=0.5: -6.173046583212077\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_smoothed_log_probability(wm, wm1, bigram_counts, alpha, vocabulary_size):\n",
    "    bigram_count = bigram_counts.get(wm1, {}).get(wm, 0)\n",
    "    unigram_count_wm1 = sum(bigram_counts.get(wm1, {}).values())\n",
    "    smoothed_probability = (bigram_count + alpha) / (unigram_count_wm1 + alpha * vocabulary_size)\n",
    "    log_probability = -math.log(smoothed_probability)\n",
    "    \n",
    "    return -log_probability\n",
    "\n",
    "# Use the function to calculate the log probability of \"academy\" followed by \"award\"\n",
    "word_wm1 = \"academy\"\n",
    "word_wm = \"award\"\n",
    "alpha_0_001 = 0.001\n",
    "alpha_0_5 = 0.5\n",
    "vocabulary_size = len(vocabulary)  # Vocabulary size from Problem 2\n",
    "\n",
    "log_prob_alpha_0_001 = calculate_smoothed_log_probability(word_wm, word_wm1, bigram_counts, alpha_0_001, vocabulary_size)\n",
    "log_prob_alpha_0_5 = calculate_smoothed_log_probability(word_wm, word_wm1, bigram_counts, alpha_0_5, vocabulary_size)\n",
    "\n",
    "print(\"Log probability of 'academy' followed by 'award' with alpha=0.001:\", log_prob_alpha_0_001)\n",
    "print(\"Log probability of 'academy' followed by 'award' with alpha=0.5:\", log_prob_alpha_0_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0ae85",
   "metadata": {},
   "source": [
    "# PROBLEM 5 – Sentence log-probability (10 pts)\n",
    "• Write a function that returns the log-probability of a sentence which is expected to be a\n",
    "negative number. To do this, assume that the probability of a word in a sequence only depends\n",
    "on the previous word. It is suggested that you use these parameters:\n",
    "    o A sentence represented as a single python string\n",
    "    o bigram counts (output of Problem 3)\n",
    "    o alpha, a smoothing parameter\n",
    "    o vocabulary size\n",
    "• Use your function to compute the log probability of these two sentences (Note that the 2nd is\n",
    "not natural English, so it should have a lower (more negative) result that the first):\n",
    "o \"this was a really great movie but it was a little too long.\"\n",
    "o \"long too little a was it but movie great really a was this.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6c4fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of sentence 1: -71.25235479495367\n",
      "Log probability of sentence 2: -145.59681149835444\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_sentence_log_probability(sentence, bigram_counts, alpha, vocabulary_size):\n",
    "    sentence_tokens = sentence.split()\n",
    "    log_probability = 0.0\n",
    "    \n",
    "    for i in range(1, len(sentence_tokens)):\n",
    "        wm1, wm = sentence_tokens[i - 1], sentence_tokens[i]\n",
    "        log_probability += calculate_smoothed_log_probability(wm, wm1, bigram_counts, alpha, vocabulary_size)\n",
    "    \n",
    "    return log_probability\n",
    "\n",
    "# Use the function to calculate the log probability of the two sentences\n",
    "sentence1 = \"this was a really great movie but it was a little too long.\"\n",
    "sentence2 = \"long too little a was it but movie great really a was this.\"\n",
    "\n",
    "alpha = 0.001  # You can adjust the smoothing parameter as needed\n",
    "vocabulary_size = len(vocabulary)  # Vocabulary size from Problem 2\n",
    "\n",
    "log_prob_sentence1 = calculate_sentence_log_probability(sentence1, bigram_counts, alpha, vocabulary_size)\n",
    "log_prob_sentence2 = calculate_sentence_log_probability(sentence2, bigram_counts, alpha, vocabulary_size)\n",
    "\n",
    "print(\"Log probability of sentence 1:\", log_prob_sentence1)\n",
    "print(\"Log probability of sentence 2:\", log_prob_sentence2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d794c",
   "metadata": {},
   "source": [
    "# PROBLEM 6 – Tuning Alpha (10pts)\n",
    "Next, use your validation set to select a good value for \"alpha\".\n",
    "• Apply the function you wrote in Problem 5 to your validation dataset using 3 different values of\n",
    "\"alpha\", such as (0.001, 0.01, 0.1). For each value, show the log-likelihood estimate of the\n",
    "validation set. That is, in your notebook show the sum of the log probabilities of all sentences.\n",
    "• Which alpha gives you the best result? To indicate your selection to the grader, save your\n",
    "selected value to a variable named \"selected_alpha\"\n",
    ". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3eb425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood Estimate (alpha=0.001): -216.8492\n",
      "Log-Likelihood Estimate (alpha=0.01): -194.0312\n",
      "Log-Likelihood Estimate (alpha=0.1): -183.0741\n",
      "Selected Alpha: 0.1\n"
     ]
    }
   ],
   "source": [
    "validation_sentences = [\n",
    "    \"this was a really great movie but it was a little too long.\",\n",
    "    \"long too little a was it but movie great really a was this.\"\n",
    "]\n",
    "\n",
    "# List of different alpha values to test\n",
    "alphas = [0.001, 0.01, 0.1]\n",
    "\n",
    "# Function to calculate the log-likelihood estimate\n",
    "def calculate_log_likelihood(alpha, sentences, bigram_counts, vocabulary_size):\n",
    "    log_likelihood = 0.0\n",
    "    for sentence in sentences:\n",
    "        log_likelihood += calculate_sentence_log_probability(sentence, bigram_counts, alpha, vocabulary_size)\n",
    "    return log_likelihood\n",
    "\n",
    "# Calculate and display the log-likelihood estimate for each alpha\n",
    "for alpha in alphas:\n",
    "    log_likelihood = calculate_log_likelihood(alpha, validation_sentences, bigram_counts, vocabulary_size)\n",
    "    print(f\"Log-Likelihood Estimate (alpha={alpha}): {round(log_likelihood, 4)}\")\n",
    "\n",
    "# Select an alpha value from the list of alphas (e.g., the third element)\n",
    "selected_alpha = alphas[2]\n",
    "\n",
    "# Print the selected alpha\n",
    "print(f\"Selected Alpha: {selected_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408aef7a",
   "metadata": {},
   "source": [
    "# PROBLEM 7 – Applying Language Models (20 pts)\n",
    "In this problem, you will classify your test set of 100 sentences by sentiment, by applying your work\n",
    "from previous problems and modeling the language of both positive and negative sentiment.\n",
    "To do this, you can follow these steps:\n",
    "• Separate your training dataset into positive and negative sentences, and compute vocabulary\n",
    "size and bigram counts for both datasets.\n",
    "• For each of the 100 sentences in your test set:\n",
    "o Compute both a \"positive sentiment score\" and a \"negative sentiment score\" using (1)\n",
    "the function you wrote in Problem 5, (2) Bayes rule, and (3) class priors as computed in\n",
    "Problem 1.\n",
    "o Compare these scores to assign a predicted sentiment label to the sentence.\n",
    "• What is the class distribution of your predicted label? That is, how often did your method\n",
    "predict positive sentiment, correctly or incorrectly? How often did it predict negative\n",
    "sentiment? Show results in your notebook.\n",
    "• Compare your predicted label to the true sentiment label. What is the accuracy of this\n",
    "experiment? That is, how often did the true and predicted label match on the test set? Show\n",
    "results in your notebook.\n",
    "For this problem, you do not need to re-tune alpha for your positive and negative datasets (although it\n",
    "may be a good idea to do so), you can re-use the value selected in Problem 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c38a710d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution of Predicted Labels:\n",
      "1    0.52\n",
      "0    0.48\n",
      "Name: predicted_label, dtype: float64\n",
      "Accuracy: 87.00%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Split the training set into positive and negative sentences\n",
    "positive_sentences = train_df[train_df['label'] == 1]['sentence']\n",
    "negative_sentences = train_df[train_df['label'] == 0]['sentence']\n",
    "\n",
    "# Count bigrams in positive and negative sentences\n",
    "positive_bigram_counts = count_bigrams(positive_sentences.apply(tokenize))\n",
    "negative_bigram_counts = count_bigrams(negative_sentences.apply(tokenize))\n",
    "\n",
    "# Calculate the prior probabilities for positive and negative classes\n",
    "positive_prior = len(positive_sentences) / len(train_df)\n",
    "negative_prior = 1 - positive_prior\n",
    "\n",
    "def classify_sentence(sentence, positive_bigram_counts, negative_bigram_counts, positive_prior, negative_prior, alpha, vocabulary_size):\n",
    "    \n",
    "    positive_log_prob = calculate_sentence_log_probability(sentence, positive_bigram_counts, alpha, vocabulary_size) + math.log(positive_prior)\n",
    "    negative_log_prob = calculate_sentence_log_probability(sentence, negative_bigram_counts, alpha, vocabulary_size) + math.log(negative_prior)\n",
    "    return 1 if positive_log_prob > negative_log_prob else 0\n",
    "\n",
    "# Apply the classification function to the test set and add predicted labels\n",
    "test_df['predicted_label'] = test_df['sentence'].apply(\n",
    "    lambda sentence: classify_sentence(sentence, positive_bigram_counts, negative_bigram_counts, positive_prior, negative_prior, selected_alpha, vocabulary_size)\n",
    ")\n",
    "\n",
    "# Calculate class distribution and accuracy\n",
    "class_distribution = test_df['predicted_label'].value_counts(normalize=True)\n",
    "accuracy = (test_df['label'] == test_df['predicted_label']).mean()\n",
    "\n",
    "# Print results\n",
    "print(\"Class Distribution of Predicted Labels:\")\n",
    "print(class_distribution)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d284e",
   "metadata": {},
   "source": [
    "# PROBLEM 8 – Markov Assumption (10 pts – Answer in Blackboard)\n",
    "• Where in this homework did you apply the Markov assumption?\n",
    "• Imagine you applied the 2nd\n",
    "-order Markov assumption, using trigrams. Do you think your\n",
    "accuracy results would increase or decrease? Why? Or, if you are not sure, give a benefit or\n",
    "drawback of using trigrams for this experiment. (Note: You do not need to rerun this experiment\n",
    "with trigrams to answer this question.)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1a2783e",
   "metadata": {},
   "source": [
    "In this assignment, we're exploring something called the Markov assumption, and we're using it to figure out the likelihood of one word following another word in Problem 4. Specifically, we're using a model that looks at pairs of words, and this falls under the first-order Markov framework. What this means is that when we're trying to predict the probability of a word in a sentence, we only pay attention to the word just before it. In other words, we're keeping it simple by assuming that a word's appearance depends only on the word that comes right before it.\n",
    "\n",
    "Now, if we want to get more complex and use the second-order Markov idea with trigrams, we would consider the probability of a word based on the two words that came before it. So, it's like estimating the likelihood of a word (let's call it \"w_m\") knowing the two words that came right before it (let's call them \"w_m-1\" and \"w_m-2\"). Moving to trigrams allows us to understand the context of the language better. Here are a few important things to remember when thinking about using trigrams:\n",
    "\n",
    "1. Trigrams capture a wider context in language modeling, which can make the language model more accurate, especially when it comes to understanding longer relationships between words in the text.\n",
    "\n",
    "2. But here's the catch – trigrams make the model more complicated. There are many more parameters to deal with, and that makes it a more sophisticated system. This can also lead to problems when there's not a lot of training data available, causing what we call \"data sparsity.\" To tackle this issue, you need to use smoothing techniques.\n",
    "\n",
    "3. Figuring out probabilities with trigrams takes more computational power compared to bigrams. This might not be a problem for small datasets, but for larger ones, it can be a headache.\n",
    "\n",
    "4. Trigram models can be harder to understand because they're capturing more intricate language patterns. On the other hand, bigram models are simpler and easier to explain.\n",
    "\n",
    "In real-world situations, whether trigrams make the language model better or worse depends on the specific dataset and what you're trying to do. If you're working with a big dataset and you can handle the complexity and the extra computational cost, trigrams might improve accuracy by understanding more context but may lead to data sparsity issues. The key is finding the right balance between how complex your model is and how much data you have when deciding which level of the Markov assumption to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
