{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59cfadc-2a20-45ce-9d0f-ae6b6c3d7d17",
   "metadata": {},
   "source": [
    "## Huffman Coding Implementation\n",
    "\n",
    "Based on: https://en.wikipedia.org/wiki/Huffman_coding\n",
    "\n",
    "1. Create a leaf node for each symbol and add it to the priority queue.\n",
    "1. While there is more than one node in the queue:\n",
    "   * Remove the two nodes of highest priority (lowest probability) from the queue\n",
    "   * Create a new internal node with these two nodes as children and with probability equal to the sum of the two nodes' probabilities.\n",
    "   * Add the new node to the queue.\n",
    "1. The remaining node is the root node and the tree is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa68afd-4350-4d50-9c49-0036f505afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk setup, run once\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from typing import Dict # for type hints \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d2730fa-0e60-47f4-9bfc-ce674f127fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(probs:Dict[str,float], verbose:bool=True)->float:\n",
    "    \"\"\"Build binary tree following Huffmann encoding algorithm\"\"\"\n",
    "    probs = probs.copy()\n",
    "\n",
    "    # initilize priority queue - lowest probability first\n",
    "    priority_queue = sorted(probs.keys(), key=probs.get)\n",
    "\n",
    "    # iteratively add new nodes by combining 2 nodes with lowest probability\n",
    "    while len(priority_queue) > 1:\n",
    "        item1 = priority_queue.pop(0)\n",
    "        item2 = priority_queue.pop(0)\n",
    "        new_node = (item1, item2)\n",
    "        probs[new_node] = probs[item1] + probs[item2]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Creating new node: P({new_node}) = {probs[new_node]:.1%}\")\n",
    "\n",
    "        # add to queue and maintain priority order: lowest prob first\n",
    "        priority_queue.append(new_node)\n",
    "        priority_queue.sort(key=probs.get)\n",
    "\n",
    "    # when 1 node remains: output as result tree\n",
    "    output_tree = priority_queue[0]\n",
    "    return output_tree\n",
    "\n",
    "\n",
    "def get_coding(node:tuple, code_prefix:str=\"\")->Dict[str,str]:\n",
    "    \"\"\"Recursively translate tree output by build_tree() to 0/1 prefix code\"\"\"\n",
    "\n",
    "    if isinstance(node, str): # end of recursion: found leaf node\n",
    "        return {node: code_prefix}\n",
    "    else:\n",
    "        left_node, right_node = node\n",
    "        left_codes = get_coding(left_node, code_prefix + \"0\")\n",
    "        right_codes = get_coding(right_node, code_prefix + \"1\")\n",
    "        return {**left_codes, **right_codes}\n",
    "\n",
    "\n",
    "def do_huffman_encoding(probs:Dict[str,float], verbose=True)->Dict[str,str]:\n",
    "    \"\"\"Apply Huffman encoding steps to input probability dictionary\"\"\"\n",
    "    \n",
    "    if verbose==True:  # show input and output\n",
    "        print(\"Input probs:\")\n",
    "        for sym, prob_sym in sorted(probs.items()):\n",
    "            print(f\"{sym}: {prob_sym:.4g}\")\n",
    "    \n",
    "    # Step 1: build binary tree\n",
    "    output_tree = build_tree(probs, verbose=verbose)\n",
    "\n",
    "    # Step 2: get prefix codes\n",
    "    output_coding = get_coding(output_tree)\n",
    "\n",
    "    if verbose==True:  # show input and output            \n",
    "        print(\"\\nTree:\", output_tree)\n",
    "        print(\"\\nEncoding:\")    \n",
    "        for sym, sym_code in sorted(output_coding.items()):\n",
    "            print(f\"{sym}: {sym_code}\")\n",
    "\n",
    "    return output_coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db434ca1-9c50-4a3c-ac89-56f467a0da24",
   "metadata": {},
   "source": [
    "## A fair coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f393abd8-5cec-44ab-a99f-73a51dcd47b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input probs:\n",
      "a: 0.5\n",
      "b: 0.5\n",
      "Creating new node: P(('a', 'b')) = 100.0%\n",
      "\n",
      "Tree: ('a', 'b')\n",
      "\n",
      "Encoding:\n",
      "a: 0\n",
      "b: 1\n",
      "\n",
      "Average encoded length: 1.0\n"
     ]
    }
   ],
   "source": [
    "events = \"ab\"\n",
    "symbol_probs = {sym:events.count(sym)/len(events) for sym in events}\n",
    "\n",
    "code_map = do_huffman_encoding(symbol_probs)\n",
    "\n",
    "expected_encoding_len = sum([symbol_probs[sym]*len(code_map[sym]) for sym in symbol_probs])\n",
    "print(\"\\nAverage encoded length:\",expected_encoding_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e1fde-84a9-4f16-aa4f-7e2acd9f9a02",
   "metadata": {},
   "source": [
    "## A fair 6-sided die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e6c243d-d989-450d-aa1a-b0c68969c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input probs:\n",
      "1: 0.1667\n",
      "2: 0.1667\n",
      "3: 0.1667\n",
      "4: 0.1667\n",
      "5: 0.1667\n",
      "6: 0.1667\n",
      "Creating new node: P(('1', '2')) = 33.3%\n",
      "Creating new node: P(('3', '4')) = 33.3%\n",
      "Creating new node: P(('5', '6')) = 33.3%\n",
      "Creating new node: P((('1', '2'), ('3', '4'))) = 66.7%\n",
      "Creating new node: P((('5', '6'), (('1', '2'), ('3', '4')))) = 100.0%\n",
      "\n",
      "Tree: (('5', '6'), (('1', '2'), ('3', '4')))\n",
      "\n",
      "Encoding:\n",
      "1: 100\n",
      "2: 101\n",
      "3: 110\n",
      "4: 111\n",
      "5: 00\n",
      "6: 01\n",
      "Average encoded length: 2.6667\n"
     ]
    }
   ],
   "source": [
    "events = \"123456\"\n",
    "symbol_probs = {sym:events.count(sym)/len(events) for sym in events}\n",
    "\n",
    "code_map = do_huffman_encoding(symbol_probs)\n",
    "\n",
    "expected_encoding_len = sum([symbol_probs[sym]*len(code_map[sym]) for sym in symbol_probs])\n",
    "print(f\"Average encoded length: {expected_encoding_len:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1466d58-d080-4ec3-ab03-f90d8f0eba11",
   "metadata": {},
   "source": [
    "## An unfair 6-sided die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f3319f2-fe23-4383-8b37-ccc279ae7d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input probs:\n",
      "1: 0.5\n",
      "2: 0.1\n",
      "3: 0.1\n",
      "4: 0.1\n",
      "5: 0.1\n",
      "6: 0.1\n",
      "Creating new node: P(('2', '3')) = 20.0%\n",
      "Creating new node: P(('4', '5')) = 20.0%\n",
      "Creating new node: P(('6', ('2', '3'))) = 30.0%\n",
      "Creating new node: P((('4', '5'), ('6', ('2', '3')))) = 50.0%\n",
      "Creating new node: P(('1', (('4', '5'), ('6', ('2', '3'))))) = 100.0%\n",
      "\n",
      "Tree: ('1', (('4', '5'), ('6', ('2', '3'))))\n",
      "\n",
      "Encoding:\n",
      "1: 0\n",
      "2: 1110\n",
      "3: 1111\n",
      "4: 100\n",
      "5: 101\n",
      "6: 110\n",
      "Average encoded length: 2.2000\n"
     ]
    }
   ],
   "source": [
    "events = \"1111123456\"\n",
    "symbol_probs = {sym:events.count(sym)/len(events) for sym in events}\n",
    "\n",
    "code_map = do_huffman_encoding(symbol_probs)\n",
    "\n",
    "expected_encoding_len = sum([symbol_probs[sym]*len(code_map[sym]) for sym in symbol_probs])\n",
    "print(f\"Average encoded length: {expected_encoding_len:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6262c0a-d4b3-4e3e-84c7-0f29b3d6b05d",
   "metadata": {},
   "source": [
    "## A snippet of English text\n",
    "\n",
    "Here symbols are **characters** (not whole words).\n",
    "\n",
    "\n",
    "Note that symbol probability is **not** uniformly distributed; symbol \"e\" is most frequent character (CORRECTION: \"e' is most frequent *vowel*, \"s\" and \"t\" are the most frequent letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21cc16b-f803-4204-80ba-8cfcecde6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input probs:\n",
      ",: 0.02778\n",
      "a: 0.05556\n",
      "b: 0.009259\n",
      "d: 0.009259\n",
      "e: 0.09259\n",
      "f: 0.0463\n",
      "g: 0.01852\n",
      "h: 0.0463\n",
      "i: 0.07407\n",
      "l: 0.009259\n",
      "m: 0.02778\n",
      "n: 0.009259\n",
      "o: 0.07407\n",
      "r: 0.009259\n",
      "s: 0.1111\n",
      "t: 0.1111\n",
      "w: 0.05556\n",
      "Creating new node: P(('b', 'r')) = 1.9%\n",
      "Creating new node: P(('d', 'l')) = 1.9%\n",
      "Creating new node: P(('n', 'g')) = 2.8%\n",
      "Creating new node: P((('b', 'r'), ('d', 'l'))) = 3.7%\n",
      "Creating new node: P(('m', ',')) = 5.6%\n",
      "Creating new node: P((('n', 'g'), (('b', 'r'), ('d', 'l')))) = 6.5%\n",
      "Creating new node: P(('h', 'f')) = 9.3%\n",
      "Creating new node: P(('w', 'a')) = 11.1%\n",
      "Creating new node: P((('m', ','), (('n', 'g'), (('b', 'r'), ('d', 'l'))))) = 12.0%\n",
      "Creating new node: P(('i', 'o')) = 14.8%\n",
      "Creating new node: P(('e', ('h', 'f'))) = 18.5%\n",
      "Creating new node: P(('t', 's')) = 22.2%\n",
      "Creating new node: P((('w', 'a'), (('m', ','), (('n', 'g'), (('b', 'r'), ('d', 'l')))))) = 23.1%\n",
      "Creating new node: P((('i', 'o'), ('e', ('h', 'f')))) = 33.3%\n",
      "Creating new node: P((('t', 's'), (('w', 'a'), (('m', ','), (('n', 'g'), (('b', 'r'), ('d', 'l'))))))) = 45.4%\n",
      "Creating new node: P(((('i', 'o'), ('e', ('h', 'f'))), (('t', 's'), (('w', 'a'), (('m', ','), (('n', 'g'), (('b', 'r'), ('d', 'l')))))))) = 78.7%\n",
      "\n",
      "Tree: ((('i', 'o'), ('e', ('h', 'f'))), (('t', 's'), (('w', 'a'), (('m', ','), (('n', 'g'), (('b', 'r'), ('d', 'l')))))))\n",
      "\n",
      "Encoding:\n",
      ",: 11101\n",
      "a: 1101\n",
      "b: 1111100\n",
      "d: 1111110\n",
      "e: 010\n",
      "f: 0111\n",
      "g: 111101\n",
      "h: 0110\n",
      "i: 000\n",
      "l: 1111111\n",
      "m: 11100\n",
      "n: 111100\n",
      "o: 001\n",
      "r: 1111101\n",
      "s: 101\n",
      "t: 100\n",
      "w: 1100\n",
      "Average encoded length: 2.9074\n"
     ]
    }
   ],
   "source": [
    "text=\"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness\"\n",
    "events = list(text.lower()) # convert text to lower-case\n",
    "\n",
    "symbol_probs = {sym:events.count(sym)/len(events) for sym in events if sym != \" \"}\n",
    "\n",
    "code_map = do_huffman_encoding(symbol_probs)\n",
    "\n",
    "expected_encoding_len = sum([symbol_probs[sym]*len(code_map[sym]) for sym in symbol_probs])\n",
    "print(f\"Average encoded length: {expected_encoding_len:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80fe42-b996-496b-8d4c-4ffc49737139",
   "metadata": {},
   "source": [
    "## The text of Lord of the Rings \n",
    "\n",
    "This example builds an encoding based on the first 10k tokens in LOTR\n",
    "\n",
    "Here are symbols are **words** and not **characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e5bd76-39e2-4ff7-8e62-a08d3d0b9b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-28 18:19:36--  https://raw.githubusercontent.com/wess/iotr/master/lotr.txt\n",
      "Resolving raw.githubusercontent.com... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3262595 (3.1M) [text/plain]\n",
      "Saving to: ‘lotr.txt.3’\n",
      "\n",
      "lotr.txt.3          100%[===================>]   3.11M  17.6MB/s    in 0.2s    \n",
      "\n",
      "2023-08-28 18:19:37 (17.6 MB/s) - ‘lotr.txt.3’ saved [3262595/3262595]\n",
      "\n",
      "####-SPECIAL NOTE: \n",
      "\n",
      " \n",
      "In this reprint several minor inaccuracies, most of them noted by readers, have \n",
      "been corrected. For example, the rune text now corresponds exactly with the runes \n",
      "on  Thror's  Map.  More  important  is  the  matter  of  Chapter  Five.  There  the  true \n",
      "story  of  the  ending  of  the  Riddle  Game,  as  it  was  eventually  revealed  (under \n",
      "pressure)  by Bilbo  to Gandalf,  is  now  given  according  to  the Red Book,  in  place \n",
      "of  the  version  Bilbo  first  gave  to  his  friends,  and  actually  set  down  in  his  diary. \n",
      "This  departure  from  truth  on  the  part  of  a  most  honest  hobbit  was  a  portent  of \n"
     ]
    }
   ],
   "source": [
    "# download text of \"Lord of the Rings\" to current working directory\n",
    "!wget https://raw.githubusercontent.com/wess/iotr/master/lotr.txt\n",
    "\n",
    "# show first 10 lines of file:\n",
    "!head lotr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b5aab9-3e29-4d76-bb37-8909a7150811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', '#', '#', '#', '-special', 'note', ':', 'in', 'this', 'reprint', 'several', 'minor', 'inaccuracies', ',', 'most', 'of', 'them', 'noted', 'by', 'readers']\n"
     ]
    }
   ],
   "source": [
    "# open file and tokenize\n",
    "with open(\"lotr.txt\") as f:\n",
    "    lotr=f.read()\n",
    "\n",
    "lotr_toks = word_tokenize(lotr.lower())\n",
    "\n",
    "print(lotr_toks[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf9c036-844b-4417-b7c8-d81ff95321b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_N_TOKENS = 10000\n",
    "\n",
    "events = lotr_toks[:FIRST_N_TOKENS]\n",
    "symbol_probs = {tok:events.count(tok)/len(events) for tok in events}\n",
    "\n",
    "# using 'verbose=False' to surpress cell output for this large dataset\n",
    "code_map = do_huffman_encoding(symbol_probs, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb1155a2-5831-4e80-bff8-14a157c20852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average encoded length: 8.4128\n"
     ]
    }
   ],
   "source": [
    "expected_encoding_len = sum([symbol_probs[tok]*len(code_map[tok]) for tok in symbol_probs])\n",
    "print(f\"Average encoded length: {expected_encoding_len:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b52e298-6578-4f3d-9fd1-7f6a526c95ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0001\n",
      ", 0111\n",
      ". 10110\n",
      "and 11101\n"
     ]
    }
   ],
   "source": [
    "# short codes:\n",
    "for symbol, code in code_map.items():\n",
    "    if len(code)<=5:\n",
    "        print(symbol, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84914392-c516-4643-bfbf-8818293f3831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-special 0100001110000\n",
      "reprint 0100001110001\n",
      "minor 0100001110010\n",
      "inaccuracies 0100001110011\n",
      "noted 0100001110100\n",
      "readers 0100001110101\n",
      "corrected 0100001110110\n",
      "example 0100001110111\n",
      "text 0100001111000\n",
      "corresponds 0100001111001\n",
      "chapter 0100001111010\n",
      "ending 0100001111011\n",
      "riddle 0100001111100\n",
      "eventually 0100001111101\n",
      "revealed 0100001111110\n",
      "pressure 0100001111111\n",
      "according 0100010000000\n",
      "version 0100010000001\n",
      "actually 0100010000010\n",
      "diary 0100010000011\n"
     ]
    }
   ],
   "source": [
    "# long codes - showing first 20\n",
    "\n",
    "SHOW_N = 20\n",
    "\n",
    "all_long_codes = [(symbol,code) for symbol, code in code_map.items() if len(code)>=13]\n",
    "\n",
    "for symbol, code in all_long_codes[:SHOW_N]:\n",
    "    print(symbol, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772a11b-cfac-4964-ade0-cd43c59e4f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session3",
   "language": "python",
   "name": "session3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
