{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9edb59",
   "metadata": {},
   "source": [
    "CS 585 – Fall 2023 – Homework 2 (100 total points) Due Wednesday September 27, 11:59pm\n",
    "\n",
    "GOALS\n",
    "\n",
    "• To perform a text classification experiment and examine the results\n",
    "\n",
    "• To become familiar the scikit-learn machine learning library\n",
    "\n",
    "• Optional exercise: To gain hands-on experience with word embeddings\n",
    "\n",
    "DATA\n",
    "\n",
    "For this homework you will build a text classification model to identify clickbait, or text headlines whose main purpose is to attract attention and entice readers to follow a link.\n",
    "\n",
    "You will use data that has been created and shared by other NLP researchers on GitHub:\n",
    "\n",
    "• Positive examples: https://github.com/pfrcks/clickbait-detection/blob/master/clickbait\n",
    "\n",
    "• Negative examples: https://github.com/pfrcks/clickbait-detection/blob/master/not-clickbait\n",
    "\n",
    "You do not need to read any research papers on clickbait detection to complete this homework, but you may enjoy reading the original publication that shared this dataset.\n",
    "\n",
    "TOOLS\n",
    "\n",
    "In this homework you are asked to use some functions from scikit-learn , an open-source python library widely used by data scientists. You should use Python to complete this homework assignment. Other programming languages will not be accepted.\n",
    "\n",
    "NOTE ON MODEL PERFORMANCE\n",
    "\n",
    "The goal of is homework is to execute an NLP experiment and present the results clearly to others (in this case, the class TAs) can read clearly. Different students will see different results, if you see lower metrics than others be assured that this will not lower your grade.\n",
    "\n",
    "WHAT TO SUBMIT\n",
    "\n",
    "Please upload or submit the following in Blackboard:\n",
    "\n",
    "• For Problems 1 and 3-7, please upload to Blackboard: o One Jupyter notebook (.ipynb file) with cell output, showing your work for both datasets. o A PDF copy of the exact same notebook (same code and same output)\n",
    "\n",
    "• For Problems 2 and 8 (no-code Q&A problems): Enter your written answers in Blackboard with your HW submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e12926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e90c15",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "• Using Python, read in the 2 clickbait datasets (See section DATA), and combine both into a single, shuffled dataset. (One function to shuffle data is numpy.random.shuffle)\n",
    "\n",
    "• Next, split your dataset into train, test, and validation datasets. Use a split of 72% train, 8% validation, and 20% test. (Which is equivalent to a 20% test set, and the remainer split 90%/10% for train and validation). o If you prefer, you may save each split as an index (list of row numbers) rather than creating 3 separate datasets.\n",
    "\n",
    "• What is the \"target rate\" of each of these three datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6eef94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/hpxmr8tj43bbn9xbcynvfny80000gn/T/ipykernel_9930/2603116280.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  non_clickbait_df = pd.read_csv(non_clickbait_file_path, delimiter='\\t', error_bad_lines=False, header=None)\n",
      "Skipping line 700: expected 1 fields, saw 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man repairs fence to contain dog, hilarity ens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long-Term Marijuana Use Has One Crazy Side Eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The water from his ear trickles into the bucke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You'll Never Guess What Nick Jonas Does in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Cruise Liners Fill All Their Unsold Cruise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Mark your calendars: Jon Stewart announces the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>OITNB's Taylor Schilling and Carrie Brownstein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Researchers have discovered the average penis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Why it may be smart to wait to put on sunscree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>What state has highest rate of rape in the cou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0    Man repairs fence to contain dog, hilarity ens...\n",
       "1    Long-Term Marijuana Use Has One Crazy Side Eff...\n",
       "2    The water from his ear trickles into the bucke...\n",
       "3    You'll Never Guess What Nick Jonas Does in the...\n",
       "4    How Cruise Liners Fill All Their Unsold Cruise...\n",
       "..                                                 ...\n",
       "809  Mark your calendars: Jon Stewart announces the...\n",
       "810  OITNB's Taylor Schilling and Carrie Brownstein...\n",
       "811  Researchers have discovered the average penis ...\n",
       "812  Why it may be smart to wait to put on sunscree...\n",
       "813  What state has highest rate of rape in the cou...\n",
       "\n",
       "[814 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Congress Slips CISA Into a Budget Bill That's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUI Arrest Sparks Controversy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It’s unconstitutional to ban the homeless from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Government Error Just Revealed Snowden Was t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A toddler got meningitis. His anti-vac parents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>US releases Guantánamo prisoner after 14 years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>Loophole means ecstasy and loads of other drug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>Astronomers Watch a Supernova and See Reruns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>In Indian Rapists’ Neighborhood, Smoldering An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>Strong earthquake jolts Islamabad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1573 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     Congress Slips CISA Into a Budget Bill That's ...\n",
       "1                         DUI Arrest Sparks Controversy\n",
       "2     It’s unconstitutional to ban the homeless from...\n",
       "3     A Government Error Just Revealed Snowden Was t...\n",
       "4     A toddler got meningitis. His anti-vac parents...\n",
       "...                                                 ...\n",
       "1568  US releases Guantánamo prisoner after 14 years...\n",
       "1569  Loophole means ecstasy and loads of other drug...\n",
       "1570       Astronomers Watch a Supernova and See Reruns\n",
       "1571  In Indian Rapists’ Neighborhood, Smoldering An...\n",
       "1572                  Strong earthquake jolts Islamabad\n",
       "\n",
       "[1573 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "clickbait_file_path = '/Users/pradaapss/Downloads/clickbait.txt'\n",
    "non_clickbait_file_path = '/Users/pradaapss/Downloads/not-clickbait.txt'\n",
    "\n",
    "# Read the datasets into Pandas DataFrames\n",
    "clickbait_df = pd.read_csv(clickbait_file_path, delimiter='\\t', header=None)\n",
    "non_clickbait_df = pd.read_csv(non_clickbait_file_path, delimiter='\\t', error_bad_lines=False, header=None)\n",
    "\n",
    "# Display the clickbait DataFrame\n",
    "display(clickbait_df)\n",
    "\n",
    "# Display the non-clickbait DataFrame\n",
    "display(non_clickbait_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a682192e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man repairs fence to contain dog, hilarity ens...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long-Term Marijuana Use Has One Crazy Side Eff...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The water from his ear trickles into the bucke...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You'll Never Guess What Nick Jonas Does in the...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Cruise Liners Fill All Their Unsold Cruise...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Mark your calendars: Jon Stewart announces the...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>OITNB's Taylor Schilling and Carrie Brownstein...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>Researchers have discovered the average penis ...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Why it may be smart to wait to put on sunscree...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>What state has highest rate of rape in the cou...</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      label\n",
       "0    Man repairs fence to contain dog, hilarity ens...  clickbait\n",
       "1    Long-Term Marijuana Use Has One Crazy Side Eff...  clickbait\n",
       "2    The water from his ear trickles into the bucke...  clickbait\n",
       "3    You'll Never Guess What Nick Jonas Does in the...  clickbait\n",
       "4    How Cruise Liners Fill All Their Unsold Cruise...  clickbait\n",
       "..                                                 ...        ...\n",
       "809  Mark your calendars: Jon Stewart announces the...  clickbait\n",
       "810  OITNB's Taylor Schilling and Carrie Brownstein...  clickbait\n",
       "811  Researchers have discovered the average penis ...  clickbait\n",
       "812  Why it may be smart to wait to put on sunscree...  clickbait\n",
       "813  What state has highest rate of rape in the cou...  clickbait\n",
       "\n",
       "[814 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Label the data as \"text\"\n",
    "clickbait_df.columns = [\"text\"]\n",
    "non_clickbait_df.columns = [\"text\"]\n",
    "\n",
    "\n",
    "# Add a \"label\" column for clickbait (1) and non-clickbait (0)\n",
    "clickbait_df[\"label\"] = 'clickbait'\n",
    "non_clickbait_df[\"label\"] = 'non-clickbait'\n",
    "\n",
    "# Combine both datasets into a single DataFrame\n",
    "combined_df = pd.concat([clickbait_df, non_clickbait_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "np.random.shuffle(combined_df.values)\n",
    "\n",
    "# Define the proportions for train, validation, and test splits\n",
    "train_ratio = 0.72\n",
    "validation_ratio = 0.08\n",
    "test_ratio = 0.20\n",
    "\n",
    "# Calculate the number of samples for each split\n",
    "total_samples = len(combined_df)\n",
    "train_samples = int(train_ratio * total_samples)\n",
    "validation_samples = int(validation_ratio * total_samples)\n",
    "test_samples = total_samples - train_samples - validation_samples\n",
    "\n",
    "# Create index lists for each split\n",
    "train_indices = list(range(train_samples))\n",
    "validation_indices = list(range(train_samples, train_samples + validation_samples))\n",
    "test_indices = list(range(train_samples + validation_samples, total_samples))\n",
    "\n",
    "display(clickbait_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2f0c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Target Rate: 35.6228%\n",
      "Validation Target Rate: 31.0526%\n",
      "Test Target Rate: 29.8539%\n"
     ]
    }
   ],
   "source": [
    "def calculate_and_print_target_rate(df, name):\n",
    "    clickbait_count = (df['label'] == 'clickbait').sum()\n",
    "    total_count = len(df)\n",
    "    target_rate = (clickbait_count / total_count) * 100\n",
    "    print(f\"{name} Target Rate: {target_rate:.4f}%\")\n",
    "\n",
    "# Split the combined dataset into train, validation, and test DataFrames\n",
    "train_df = combined_df.iloc[train_indices]\n",
    "validation_df = combined_df.iloc[validation_indices]\n",
    "test_df = combined_df.iloc[test_indices]\n",
    "\n",
    "# Calculate and print the target rates\n",
    "calculate_and_print_target_rate(train_df, \"Train\")\n",
    "calculate_and_print_target_rate(validation_df, \"Validation\")\n",
    "calculate_and_print_target_rate(test_df, \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccde696",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "Baseline Performance (10 pts – Answer in Blackboard)\n",
    "\n",
    "• Assume you have a trivial baseline classifier that flags every text presented to it as clickbait.\n",
    "What is the precision, recall, and F1-score of such a classifier on your test set? Do you think\n",
    "there is another good baseline classifier that would give you higher F-1 score? "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab025f25",
   "metadata": {},
   "source": [
    "In a trivial baseline classifier scenario, where every text is labeled as clickbait, our precision score drops to zero. Precision is calculated as the ratio of true positives to the sum of true positives and false positives. \n",
    "\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "In this case, since there are no true positives (as everything is labeled as clickbait), the precision score becomes undefined. i.e., 0 / (0 + lots of false positives) = 0\n",
    "\n",
    "Similarly, recall, which is calculated as the ratio of true positives to the sum of true positives and false negatives, is zero. When everything is classified as clickbait, the classifier fails to recognize any true positives in the dataset.\n",
    "\n",
    "Recall = True Positives / (True Positives + False Negatives)\n",
    "= 0 / (0 + lots of false negatives) = 0 \n",
    "\n",
    "The F1 score, representing a harmonic balance between precision and recall, also takes a similarly dismal turn.\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "= 2 * (0 * 0) / (0 + 0) = 0, results in a zero F1 score since both precision and recall are zero in this context.\n",
    "\n",
    "Regarding the potential for a more effective baseline classifier, one option is the random classifier, which assigns labels based on the class distribution in the dataset. Another choice is logistic regression. Logistic regression can serve as a solid baseline classifier, particularly if there are noticeable linear relationships or distinguishing features that can help differentiate clickbait from non-clickbait content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a3a6a",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Training a single Bag-of-Words (BOW) Text Classifier (20 pts)\n",
    "\n",
    "• Using scikit-learn pipelines module, create a Pipeline to train a BOW naïve bayes model. We\n",
    "suggest the classes CountVectorizer and MultinomialNB. Include both unigrams and bigrams in\n",
    "your model in your vectorizer vocabulary (see parameter: ngram_range)\n",
    "\n",
    "• Fit your classifier on your training set\n",
    "\n",
    "• Compute the precision, recall, and F1-score on both your training and validation datasets using\n",
    "functions in sklearn.metrics. Show results in your notebook. Use \"clickbait\" is your target class\n",
    "(I.e., y=1 for clickbait and y=0 for non-clickbait)\n",
    "ALTERNATIVE: If you are already well-versed in Naïve Bayes, you may select another bag-of-words\n",
    "classifier for this problem. Your method should have some way to select top features or key indicators,\n",
    "mapped to words or n-grams in your vocabulary, so that you can complete the remaining problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7204806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision: 99.0291%\n",
      "Training Recall: 100.0000%\n",
      "Training F1-Score: 99.5122%\n",
      "\t\n",
      "Validation Precision: 83.3333%\n",
      "Validation Recall: 93.2203%\n",
      "Validation F1-Score: 88.0000%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def evaluate_model(train_df, validation_df, pos_label='clickbait'):\n",
    "    # Create a pipeline with CountVectorizer and MultinomialNB\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    X_train, y_train = train_df['text'], train_df['label']\n",
    "    X_validation, y_validation = validation_df['text'], validation_df['label']\n",
    "    \n",
    "    # Fit the classifier on the training set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_validation_pred = pipeline.predict(X_validation)\n",
    "\n",
    "    # Compute precision, recall, and F1-score for training and validation sets\n",
    "    metrics_train = precision_recall_fscore_support(y_train, y_train_pred, pos_label=pos_label, average='binary')\n",
    "    metrics_validation = precision_recall_fscore_support(y_validation, y_validation_pred, pos_label=pos_label, average='binary')\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Training Precision: {:.4f}%\".format(metrics_train[0] * 100))\n",
    "    print(\"Training Recall: {:.4f}%\".format(metrics_train[1] * 100))\n",
    "    print(\"Training F1-Score: {:.4f}%\".format(metrics_train[2] * 100))\n",
    "    print('\\t')\n",
    "    print(\"Validation Precision: {:.4f}%\".format(metrics_validation[0] * 100))\n",
    "    print(\"Validation Recall: {:.4f}%\".format(metrics_validation[1] * 100))\n",
    "    print(\"Validation F1-Score: {:.4f}%\".format(metrics_validation[2] * 100))\n",
    "\n",
    "# Assuming you have train_df and validation_df\n",
    "evaluate_model(train_df, validation_df, pos_label='clickbait')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bc396",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Hyperparameter Tuning (20 pts)\n",
    "Using the ParameterGrid class, run a small grid search where you vary at least 3 parameters of your\n",
    "model\n",
    "\n",
    "• max_df for your count vectorizer (threshold to filter document frequency)\n",
    "\n",
    "• alpha or smoothing of your NaïveBayes model\n",
    "\n",
    "• One other parameter of your choice. This can be non-numeric; for example, you can consider a\n",
    "model with and without bigrams (see parameter \"ngram\" in class CountVectorizer)\n",
    "\n",
    "Show metrics on your validation set for precision, recall, and F1-score. If your grid search is very large\n",
    "(>50 rows) you may limit output to the highest and lowest results. \n",
    "ALTERNATIVE – If you used a method other than Naïve Bayes in Problem 3, then be sure it is clear what\n",
    "metrics you tuned in Problem 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4781f867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  precision_clickbait  \\\n",
      "0   {'classifier__alpha': 0.1, 'vectorizer__max_df...             0.835821   \n",
      "2   {'classifier__alpha': 0.1, 'vectorizer__max_df...             0.835821   \n",
      "4   {'classifier__alpha': 0.1, 'vectorizer__max_df...             0.835821   \n",
      "7   {'classifier__alpha': 1.0, 'vectorizer__max_df...             0.833333   \n",
      "11  {'classifier__alpha': 1.0, 'vectorizer__max_df...             0.833333   \n",
      "10  {'classifier__alpha': 1.0, 'vectorizer__max_df...             0.833333   \n",
      "8   {'classifier__alpha': 1.0, 'vectorizer__max_df...             0.833333   \n",
      "9   {'classifier__alpha': 1.0, 'vectorizer__max_df...             0.833333   \n",
      "6   {'classifier__alpha': 1.0, 'vectorizer__max_df...             0.833333   \n",
      "1   {'classifier__alpha': 0.1, 'vectorizer__max_df...             0.808824   \n",
      "5   {'classifier__alpha': 0.1, 'vectorizer__max_df...             0.808824   \n",
      "3   {'classifier__alpha': 0.1, 'vectorizer__max_df...             0.808824   \n",
      "13  {'classifier__alpha': 10.0, 'vectorizer__max_d...             0.923077   \n",
      "15  {'classifier__alpha': 10.0, 'vectorizer__max_d...             0.923077   \n",
      "17  {'classifier__alpha': 10.0, 'vectorizer__max_d...             0.923077   \n",
      "12  {'classifier__alpha': 10.0, 'vectorizer__max_d...             0.921569   \n",
      "14  {'classifier__alpha': 10.0, 'vectorizer__max_d...             0.921569   \n",
      "16  {'classifier__alpha': 10.0, 'vectorizer__max_d...             0.921569   \n",
      "\n",
      "    recall_clickbait  f1_score_clickbait  precision_non_clickbait  \\\n",
      "0           0.949153            0.888889                 0.975610   \n",
      "2           0.949153            0.888889                 0.975610   \n",
      "4           0.949153            0.888889                 0.975610   \n",
      "7           0.932203            0.880000                 0.967742   \n",
      "11          0.932203            0.880000                 0.967742   \n",
      "10          0.932203            0.880000                 0.967742   \n",
      "8           0.932203            0.880000                 0.967742   \n",
      "9           0.932203            0.880000                 0.967742   \n",
      "6           0.932203            0.880000                 0.967742   \n",
      "1           0.932203            0.866142                 0.967213   \n",
      "5           0.932203            0.866142                 0.967213   \n",
      "3           0.932203            0.866142                 0.967213   \n",
      "13          0.813559            0.864865                 0.920290   \n",
      "15          0.813559            0.864865                 0.920290   \n",
      "17          0.813559            0.864865                 0.920290   \n",
      "12          0.796610            0.854545                 0.913669   \n",
      "14          0.796610            0.854545                 0.913669   \n",
      "16          0.796610            0.854545                 0.913669   \n",
      "\n",
      "    recall_non_clickbait  f1_score_non_clickbait  \n",
      "0               0.916031                0.944882  \n",
      "2               0.916031                0.944882  \n",
      "4               0.916031                0.944882  \n",
      "7               0.916031                0.941176  \n",
      "11              0.916031                0.941176  \n",
      "10              0.916031                0.941176  \n",
      "8               0.916031                0.941176  \n",
      "9               0.916031                0.941176  \n",
      "6               0.916031                0.941176  \n",
      "1               0.900763                0.932806  \n",
      "5               0.900763                0.932806  \n",
      "3               0.900763                0.932806  \n",
      "13              0.969466                0.944238  \n",
      "15              0.969466                0.944238  \n",
      "17              0.969466                0.944238  \n",
      "12              0.969466                0.940741  \n",
      "14              0.969466                0.940741  \n",
      "16              0.969466                0.940741  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define functions for preprocessing and evaluation\n",
    "def preprocess_data(df):\n",
    "    X = df['text']\n",
    "    y = df['label']\n",
    "    return X, y\n",
    "\n",
    "def evaluate_pipeline(pipeline, X, y):\n",
    "    y_pred = pipeline.predict(X)\n",
    "    class_labels = ['clickbait', 'non-clickbait']\n",
    "    precision = precision_score(y, y_pred, labels=class_labels, average=None)\n",
    "    recall = recall_score(y, y_pred, labels=class_labels, average=None)\n",
    "    f1 = f1_score(y, y_pred, labels=class_labels, average=None)\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Data preparation\n",
    "X_train, y_train = preprocess_data(train_df)\n",
    "X_validation, y_validation = preprocess_data(validation_df)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'vectorizer__max_df': [0.5, 0.75, 1.0],\n",
    "    'classifier__alpha': [0.1, 1.0, 10.0],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate through the parameter grid\n",
    "for params in ParameterGrid(param_grid):\n",
    "    vectorizer_params = {\n",
    "        'max_df': params['vectorizer__max_df'],\n",
    "        'ngram_range': params['vectorizer__ngram_range']\n",
    "    }\n",
    "    classifier_params = {\n",
    "        'alpha': params['classifier__alpha']\n",
    "    }\n",
    "\n",
    "    # Create a new pipeline with the specified parameters\n",
    "    vectorizer = CountVectorizer(**vectorizer_params)\n",
    "    classifier = MultinomialNB(**classifier_params)\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on the training set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    precision, recall, f1 = evaluate_pipeline(pipeline, X_validation, y_validation)\n",
    "\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'precision_clickbait': precision[0],\n",
    "        'recall_clickbait': recall[0],\n",
    "        'f1_score_clickbait': f1[0],\n",
    "        'precision_non_clickbait': precision[1],\n",
    "        'recall_non_clickbait': recall[1],\n",
    "        'f1_score_non_clickbait': f1[1],\n",
    "    })\n",
    "\n",
    "# Print the results (sorted by F1-score for clickbait class)\n",
    "results_df = pd.DataFrame(results)\n",
    "sorted_results = results_df.sort_values(by='f1_score_clickbait', ascending=False)\n",
    "print(sorted_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b27fcf",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "\n",
    "Model selection (10pts)\n",
    "\n",
    "Using these validation-set metrics from the previous problem, choose one model as your selected\n",
    "model. It is up to you how to choose this model; one approach is to choose the model that shows the\n",
    "highest F1-score on your training set.\n",
    "\n",
    "Next apply your selected model to your test set and compute precision, recall and F1. Show results in\n",
    "your notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc12f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision (clickbait): 83.2215%\n",
      "Test Recall (clickbait): 86.7133%\n",
      "Test F1-Score (clickbait): 84.9315%\n",
      "\n",
      "Test Precision (non-clickbait): 94.2424%\n",
      "Test Recall (non-clickbait): 92.5595%\n",
      "Test F1-Score (non-clickbait): 93.3934%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Find the model with the highest F1-score for the 'clickbait' class on the validation set\n",
    "best_model_idx = sorted_results.index[0]\n",
    "\n",
    "# Retrieve the best model's parameters\n",
    "best_params = sorted_results.loc[best_model_idx, 'params']\n",
    "\n",
    "# Extract the best parameters for vectorizer and classifier\n",
    "vectorizer_params = best_params['vectorizer__max_df'], best_params['vectorizer__ngram_range']\n",
    "classifier_params = best_params['classifier__alpha']\n",
    "\n",
    "# Create the best model pipeline using the selected parameters\n",
    "best_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(max_df=vectorizer_params[0], ngram_range=vectorizer_params[1])),\n",
    "    ('classifier', MultinomialNB(alpha=classifier_params))\n",
    "])\n",
    "\n",
    "# Fit the best model on the training set\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['label']\n",
    "y_test_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for the test set\n",
    "labels = ['clickbait', 'non-clickbait']\n",
    "test_precision = precision_score(y_test, y_test_pred, labels=labels, average=None)\n",
    "test_recall = recall_score(y_test, y_test_pred, labels=labels, average=None)\n",
    "test_f1 = f1_score(y_test, y_test_pred, labels=labels, average=None)\n",
    "\n",
    "# Display the results for the test set\n",
    "for label in labels:\n",
    "    label_idx = labels.index(label)\n",
    "    precision = round(test_precision[label_idx] * 100, 4)\n",
    "    recall = round(test_recall[label_idx] * 100, 4)\n",
    "    f1 = round(test_f1[label_idx] * 100, 4)\n",
    "    \n",
    "    print(f\"Test Precision ({label}): {precision}%\")\n",
    "    print(f\"Test Recall ({label}): {recall}%\")\n",
    "    print(f\"Test F1-Score ({label}): {f1}%\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0026dd",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "\n",
    "Key Indicators (10pts)\n",
    "\n",
    "Using the log-probabilities of the model you selected in the previous problem, select 5 words that are\n",
    "strong Clickbait indicators. That is, if you needed to filter headlines based on a single word, without a\n",
    "machine learning model, then these words would be good options. Show this list of keywords in your\n",
    "notebook.\n",
    "\n",
    "You can choose how to handle bigrams (e.g., \"win<space>big\"); you may choose to ignore them and\n",
    "only select unigram vocabulary words as key indicators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f3c561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Clickbait Indicator Words:\n",
      "['to' 'in' 'of' 'for' 'the']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Get the trained Naïve Bayes classifier and CountVectorizer from the best pipeline\n",
    "classifier = best_pipeline.named_steps['classifier']\n",
    "vectorizer = best_pipeline.named_steps['vectorizer']\n",
    "\n",
    "# Get the vocabulary from the CountVectorizer\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get the log probabilities of words for the \"clickbait\" class\n",
    "log_probabilities = classifier.feature_log_prob_[1]\n",
    "\n",
    "# Create a DataFrame to store words and their log probabilities\n",
    "word_probabilities_df = pd.DataFrame({'Word': vocab, 'Log Probability (Clickbait)': log_probabilities})\n",
    "\n",
    "# Sort the DataFrame by log probabilities in descending order\n",
    "sorted_word_probabilities = word_probabilities_df.sort_values(by='Log Probability (Clickbait)', ascending=False)\n",
    "\n",
    "# Get the top 5 words with the highest log probabilities\n",
    "top_clickbait_words = sorted_word_probabilities.head(5)\n",
    "\n",
    "# Display the list of top clickbait indicator words\n",
    "top_clickbait_words_list = top_clickbait_words['Word'].values\n",
    "print(\"Top 5 Clickbait Indicator Words:\")\n",
    "print(top_clickbait_words_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4557487",
   "metadata": {},
   "source": [
    "# Problem 7\n",
    "\n",
    "Regular expressions (10pts)\n",
    "\n",
    "Your IT department has reached out to you because they heard you can help them find clickbait. They\n",
    "are interested in your machine learning model, but they need a solution today.\n",
    "\n",
    "• Write a regular expression that checks if any of the keywords from the previous problem are\n",
    "found in the text. You should write one regular expression that detects any of your top 5\n",
    "keywords. Your regular expression should be aware of word boundaries in some way. That is,\n",
    "the keyword \"win\" should not be detected in the text \"Gas prices up in winter months\".\n",
    "\n",
    "• Using the python re library – apply your function to your test set. (See function re.search). What\n",
    "is the precision and recall of this classifier? Show your results in your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6227634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2857142857142857\n",
      "Recall: 0.6573426573426573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a regular expression pattern to match any of these keywords with word boundaries\n",
    "pattern = r'\\b(?:' + '|'.join(re.escape(keyword) for keyword in top_clickbait_words_list) + r')\\b'\n",
    "\n",
    "# Initialize counters for true positives, false positives, and false negatives\n",
    "tp, fp, fn = 0, 0, 0\n",
    "\n",
    "# Iterate through the test set and apply the regular expression to each text\n",
    "for text, label in zip(X_test, y_test):\n",
    "    matched = re.search(pattern, text, flags=re.IGNORECASE)  # Case insensitive match\n",
    "    if matched and label == 'clickbait':\n",
    "        tp += 1  # True positive\n",
    "    elif matched:\n",
    "        fp += 1  # False positive\n",
    "    elif label == 'clickbait':\n",
    "        fn += 1  # False negative\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "\n",
    "# Display the results\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012094b",
   "metadata": {},
   "source": [
    "# Problem 8\n",
    "\n",
    "\n",
    "Comparing results (15pts – Answer in Blackboard)\n",
    "\n",
    "• Compare your rules-based classifier from the previous problem with your machine-learning\n",
    "solution. Which classifier showed the best model metrics? Why do you think it performed the\n",
    "best? How did both compare to your trivial baseline (Problem 2)?\n",
    "\n",
    "• If you had more time to try to improve this clickbait detection solution, what would you\n",
    "explore? (There is no single correct answer to this question; review your results and come up\n",
    "with your own ideas)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65f2609b",
   "metadata": {},
   "source": [
    "Comparing the rule-based classifier to the machine learning model, the ML model achieved superior performance on key metrics like precision, recall and F1-score. This is likely because the machine learning model was able to learn more complex patterns from the training data rather than just matching on a few keywords. The rule-based classifier matches based on surface patterns, while the ML model incorporates contextual relationships i.e., by learning indicative features. \n",
    "\n",
    "Both models performed much better than the trivial \"all clickbait\" baseline, which had 0% precision and recall. The ML pipeline was the best, with F1-score in the 90-95% range based on the validation and test results. The rule-based classifier, offered a quick and short-term solution but was limited by its rules, resulting in an F1-score of only 50-60%.\n",
    "\n",
    "I would like to explore techniques below to improve this clickbait detection solution:\n",
    "\n",
    "1. Trying deep learning models like CNNs or LSTMs to learn semantic features from word embeddings.\n",
    "2. Experimenting with different preprocessing and feature engineering approaches\n",
    "3. Incorporating additional metadata like source, author, etc. as features\n",
    "4. Implementing active learning methodologies to identify and label the most informative samples, thus enhancing the quality of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c3ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
