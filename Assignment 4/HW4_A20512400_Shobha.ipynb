{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67edfeec",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "Reading the data in CoNLL format (20pts)\n",
    "Note that the NCBI Disease Corpus (See section DATA above) is already split into train, development,\n",
    "and test datasets. You will use the train and test datasets in this homework.\n",
    "As noted above, you should use files in the \"ncbi-disease/conll\" subfolder. In this file format, a blank line\n",
    "indicates the start of a new sequence.\n",
    "\n",
    "• Write a function that reads a .tsv files in the CoNLL format and returns two “list of lists” as\n",
    "output:\n",
    "\n",
    "    o A list of sequences of tokens, where a single token may be a word or punctuation.\n",
    "    o A list of sequences of tags, representing token-level annotation. You should see these 3\n",
    "    tags in your data (“B-Disease”, “I-Disease”, “O”)\n",
    "\n",
    "• Apply your function to train.tsv and test.tsv. To show you have read in the data correctly, show\n",
    "the following in your notebook output:\n",
    "\n",
    "    o The number of sequences in train and test. (You should see 5432 sequences in train and\n",
    "    940 sequences in test.)\n",
    "    o The tokens and tags of the first sequence in the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2926804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in /Users/pradaapss/anaconda3/lib/python3.11/site-packages (0.3.6)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /Users/pradaapss/anaconda3/lib/python3.11/site-packages (from sklearn-crfsuite) (0.9.9)\n",
      "Requirement already satisfied: six in /Users/pradaapss/anaconda3/lib/python3.11/site-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Requirement already satisfied: tabulate in /Users/pradaapss/anaconda3/lib/python3.11/site-packages (from sklearn-crfsuite) (0.8.10)\n",
      "Requirement already satisfied: tqdm>=2.0 in /Users/pradaapss/anaconda3/lib/python3.11/site-packages (from sklearn-crfsuite) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a996dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cee398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences in train: 5432\n",
      "Tokens of the first sequence in the train dataset:\n",
      "['Identification', 'of', 'APC2', ',', 'a', 'homologue', 'of', 'the', 'adenomatous', 'polyposis', 'coli', 'tumour', 'suppressor', '.']\n",
      "Tags of the first sequence in the train dataset:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O', 'O']\n",
      "Number of sequences in test: 940\n",
      "Tokens of the first sequence in the test dataset:\n",
      "['Clustering', 'of', 'missense', 'mutations', 'in', 'the', 'ataxia', '-', 'telangiectasia', 'gene', 'in', 'a', 'sporadic', 'T', '-', 'cell', 'leukaemia', '.']\n",
      "Tags of the first sequence in the test dataset:\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O']\n"
     ]
    }
   ],
   "source": [
    "def read_conll_file(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        sentence = []\n",
    "        sentence_labels = []\n",
    "\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line:\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(sentence_labels)\n",
    "                sentence = []\n",
    "                sentence_labels = []\n",
    "            else:\n",
    "                token, label = line.split(\"\\t\")\n",
    "                sentence.append(token)\n",
    "                sentence_labels.append(label)\n",
    "\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "            labels.append(sentence_labels)\n",
    "\n",
    "    return sentences, labels\n",
    "\n",
    "def print_sequence_info(name, sentences, labels):\n",
    "    print(f\"Number of sequences in {name}: {len(sentences)}\")\n",
    "    if len(sentences) > 0:\n",
    "        print(f\"Tokens of the first sequence in the {name} dataset:\")\n",
    "        print(sentences[0])\n",
    "        print(f\"Tags of the first sequence in the {name} dataset:\")\n",
    "        print(labels[0])\n",
    "\n",
    "train_file_path = \"/Users/pradaapss/Desktop/Semester 3/CS 585 NLP/Assignment 4/ncbi disease/train.tsv\"\n",
    "test_file_path = \"/Users/pradaapss/Desktop/Semester 3/CS 585 NLP/Assignment 4/ncbi disease/test.tsv\"\n",
    "\n",
    "train_sentences, train_labels = read_conll_file(train_file_path)\n",
    "test_sentences, test_labels = read_conll_file(test_file_path)\n",
    "\n",
    "print_sequence_info(\"train\", train_sentences, train_labels)\n",
    "print_sequence_info(\"test\", test_sentences, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f018130b",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "In this problem you will examine the data that you read into memory in the previous problem. Using the\n",
    "training dataset for analysis, show the following in your notebook output:\n",
    "\n",
    "• The count of each of the 3 tags in the training data: “B-Disease”, “I-Disease”, and “O”. Note that\n",
    "the most frequent token is \"O\", since most words are not part of a disease mention.\n",
    "\n",
    "• The 20 most common words/tokens that appear with the tags “B-Disease” or “I-Disease”. That\n",
    "is, show words that often appear disease mentions. (You may show frequent “B-Disease” and “I-\n",
    "Disease” words separately, or you may combine them into a single list.)\n",
    "\n",
    "• OPTIONAL: Any other data exploration you would like to perform. For example, you may want to\n",
    "print and read a small sample of token sequences, to become familiar with the data.\n",
    "Review the list of words that commonly appear in disease mentions. Do you see any patterns? (You do\n",
    "not need to answer in writing, but it may be helpful in Problem 3 where you design a feature.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ed8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag counts in training data:\n",
      "Counter({'O': 124819, 'I-Disease': 6122, 'B-Disease': 5145})\n",
      "20 most common words/tokens with 'B-Disease' or 'I-Disease' tags:\n",
      "[('-', 636), ('deficiency', 322), ('syndrome', 281), ('cancer', 269), ('disease', 256), ('of', 178), ('dystrophy', 176), ('breast', 151), ('ovarian', 132), ('X', 122), ('and', 120), ('DM', 120), ('ALD', 114), ('DMD', 110), ('APC', 100), ('disorder', 94), ('muscular', 94), ('G6PD', 92), ('linked', 81), ('the', 78)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_tag_frequency(labels):\n",
    "    tag_counts = Counter(tag for label_list in labels for tag in label_list)\n",
    "    return tag_counts\n",
    "\n",
    "def count_common_words_with_tags(tokens, labels, target_tags, num_common=20):\n",
    "    word_counts = Counter(tokens[i] for i, label in enumerate(labels) if label in target_tags)\n",
    "    common_words = word_counts.most_common(num_common)\n",
    "    return common_words\n",
    "\n",
    "tag_counts = count_tag_frequency(train_labels)\n",
    "print(\"Tag counts in training data:\")\n",
    "print(tag_counts)\n",
    "\n",
    "flat_train_tokens = [token for sentence in train_sentences for token in sentence]\n",
    "flat_train_labels = [label for labels in train_labels for label in labels]\n",
    "\n",
    "target_tags = [\"B-Disease\", \"I-Disease\"]\n",
    "common_words = count_common_words_with_tags(flat_train_tokens, flat_train_labels, target_tags)\n",
    "\n",
    "print(\"20 most common words/tokens with 'B-Disease' or 'I-Disease' tags:\")\n",
    "print(common_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3700a5",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "In this problem, you will build the features that you will use in your CRF model. You may find it helpful to\n",
    "refer to this demo notebook, to understand how to work with the python-crfsuite library.\n",
    "\n",
    "• Write a function that takes two inputs:\n",
    "\n",
    "    o A sequence of tokens\n",
    "    o An integer position, pointing to one token in that sequence.\n",
    "    and returns a list of features, represented as a list of strings. At minimum, include these\n",
    "    features:\n",
    "    o The current word/token in lower case\n",
    "    o The suffix (last 3 characters) of the current word\n",
    "    o The previous word/token (position i-1) or “BOS” if at the beginning of the sequence\n",
    "    o The next word/token (position i+1), or “EOS” if at the beginning of the sequence\n",
    "    o At least one other feature of your choice\n",
    "    \n",
    "• Apply your function your train and test token sequences (from output of Problem 1).\n",
    "\n",
    "• To show that you have completed this step, apply your output to the first 3 words in the first\n",
    "sequence of the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f805a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w0.lower=identification', 'w0.suffix3=ion', 'w-1=BOS', 'w+1=of', 'len=14']\n",
      "['w0.lower=of', 'w0.suffix3=of', 'w-1=Identification', 'w+1=APC2', 'len=2']\n",
      "['w0.lower=apc2', 'w0.suffix3=PC2', 'w-1=of', 'w+1=,', 'len=4']\n"
     ]
    }
   ],
   "source": [
    "def extract_features(tokens, position):\n",
    "    features = []\n",
    "    \n",
    "    current_token = tokens[position]\n",
    "    \n",
    "    previous_token = tokens[position - 1] if position > 0 else \"BOS\"\n",
    "    next_token = tokens[position + 1] if position < len(tokens) - 1 else \"EOS\"\n",
    "\n",
    "    suffix = current_token[-3:]\n",
    "    \n",
    "    # Add features to the list\n",
    "    features.append(f'w0.lower={current_token.lower()}')  \n",
    "    features.append(f'w0.suffix3={suffix}')  \n",
    "    features.append(f'w-1={previous_token}')  \n",
    "    features.append(f'w+1={next_token}')  \n",
    "    features.append(f'len={len(current_token)}')  \n",
    "    \n",
    "    return features\n",
    "\n",
    "sequence = train_sentences[0]\n",
    "\n",
    "for i in range(3):\n",
    "    features = extract_features(sequence, i)\n",
    "    print(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f3f16",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "In this problem, you will train a CRF model and evaluate it using metrics computed over individual tags.\n",
    "\n",
    "• Using the python-crfsuite library, train a CRF sequential tagging model using feature sequences\n",
    "that you built in the previous step. Using your training data as input.\n",
    "\n",
    "• Apply your model to your test dataset to generate predicted tag sequences.\n",
    "\n",
    "• For each of the 3 labels (\"B-Disease\", \"I-Disease\", and “O\") show precision, recall, f1-score. [You\n",
    "may use the sckit-learn function classification_report to complete this step. You may also want\n",
    "to “flatten” both the true and predicted tags into a single list of tags to apply this function.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026dfb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 32892\n",
      "Seconds required: 0.091\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 1.000000\n",
      "c2: 0.001000\n",
      "num_memories: 6\n",
      "max_iterations: 50\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "***** Iteration #1 *****\n",
      "Loss: 59267.137232\n",
      "Feature norm: 1.000000\n",
      "Error norm: 56241.322611\n",
      "Active features: 19837\n",
      "Line search trials: 1\n",
      "Line search step: 0.000009\n",
      "Seconds required for this iteration: 0.037\n",
      "\n",
      "***** Iteration #2 *****\n",
      "Loss: 39509.015314\n",
      "Feature norm: 2.026043\n",
      "Error norm: 9310.085362\n",
      "Active features: 14762\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Iteration #3 *****\n",
      "Loss: 38423.293001\n",
      "Feature norm: 1.943124\n",
      "Error norm: 7655.084781\n",
      "Active features: 13853\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Iteration #4 *****\n",
      "Loss: 36309.057587\n",
      "Feature norm: 1.801733\n",
      "Error norm: 11639.093703\n",
      "Active features: 8725\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Iteration #5 *****\n",
      "Loss: 34712.207836\n",
      "Feature norm: 1.954942\n",
      "Error norm: 7777.134813\n",
      "Active features: 8937\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Iteration #6 *****\n",
      "Loss: 27230.827998\n",
      "Feature norm: 3.338013\n",
      "Error norm: 3892.648267\n",
      "Active features: 8397\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #7 *****\n",
      "Loss: 25059.652233\n",
      "Feature norm: 5.466219\n",
      "Error norm: 20402.488185\n",
      "Active features: 8379\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #8 *****\n",
      "Loss: 22670.668915\n",
      "Feature norm: 5.338074\n",
      "Error norm: 2442.578219\n",
      "Active features: 10521\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #9 *****\n",
      "Loss: 21867.504100\n",
      "Feature norm: 5.807523\n",
      "Error norm: 2265.300567\n",
      "Active features: 10191\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #10 *****\n",
      "Loss: 17556.925329\n",
      "Feature norm: 9.546485\n",
      "Error norm: 2232.712805\n",
      "Active features: 8085\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #11 *****\n",
      "Loss: 15792.679319\n",
      "Feature norm: 11.742872\n",
      "Error norm: 1260.891996\n",
      "Active features: 7774\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #12 *****\n",
      "Loss: 14344.711292\n",
      "Feature norm: 15.214771\n",
      "Error norm: 4719.062338\n",
      "Active features: 7652\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #13 *****\n",
      "Loss: 13204.588039\n",
      "Feature norm: 17.433069\n",
      "Error norm: 1694.604858\n",
      "Active features: 7795\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #14 *****\n",
      "Loss: 12191.135964\n",
      "Feature norm: 19.685694\n",
      "Error norm: 1338.346427\n",
      "Active features: 7743\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #15 *****\n",
      "Loss: 11063.402530\n",
      "Feature norm: 22.552418\n",
      "Error norm: 635.184949\n",
      "Active features: 7660\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #16 *****\n",
      "Loss: 9947.875384\n",
      "Feature norm: 26.071888\n",
      "Error norm: 1301.620157\n",
      "Active features: 7416\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #17 *****\n",
      "Loss: 9373.970542\n",
      "Feature norm: 28.716003\n",
      "Error norm: 2037.584882\n",
      "Active features: 7182\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #18 *****\n",
      "Loss: 8882.397045\n",
      "Feature norm: 31.203056\n",
      "Error norm: 364.490326\n",
      "Active features: 7095\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #19 *****\n",
      "Loss: 8506.101352\n",
      "Feature norm: 33.279136\n",
      "Error norm: 391.600703\n",
      "Active features: 6966\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #20 *****\n",
      "Loss: 8156.482096\n",
      "Feature norm: 37.517293\n",
      "Error norm: 1913.591117\n",
      "Active features: 6268\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #21 *****\n",
      "Loss: 7760.600919\n",
      "Feature norm: 38.673687\n",
      "Error norm: 462.879067\n",
      "Active features: 6343\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #22 *****\n",
      "Loss: 7613.458922\n",
      "Feature norm: 39.692972\n",
      "Error norm: 507.732537\n",
      "Active features: 6261\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #23 *****\n",
      "Loss: 7307.051870\n",
      "Feature norm: 42.565448\n",
      "Error norm: 227.514154\n",
      "Active features: 5858\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #24 *****\n",
      "Loss: 7066.416427\n",
      "Feature norm: 44.413065\n",
      "Error norm: 444.107631\n",
      "Active features: 5478\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #25 *****\n",
      "Loss: 6965.549073\n",
      "Feature norm: 45.098358\n",
      "Error norm: 1280.497647\n",
      "Active features: 5315\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.039\n",
      "\n",
      "***** Iteration #26 *****\n",
      "Loss: 6811.920270\n",
      "Feature norm: 46.929861\n",
      "Error norm: 434.977573\n",
      "Active features: 5237\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #27 *****\n",
      "Loss: 6709.826087\n",
      "Feature norm: 47.881971\n",
      "Error norm: 108.588755\n",
      "Active features: 5161\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #28 *****\n",
      "Loss: 6530.901751\n",
      "Feature norm: 50.695396\n",
      "Error norm: 194.489317\n",
      "Active features: 4921\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #29 *****\n",
      "Loss: 6460.843849\n",
      "Feature norm: 52.662281\n",
      "Error norm: 549.122886\n",
      "Active features: 4655\n",
      "Line search trials: 2\n",
      "Line search step: 0.500000\n",
      "Seconds required for this iteration: 0.039\n",
      "\n",
      "***** Iteration #30 *****\n",
      "Loss: 6343.037568\n",
      "Feature norm: 54.323545\n",
      "Error norm: 193.144170\n",
      "Active features: 4569\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #31 *****\n",
      "Loss: 6250.230975\n",
      "Feature norm: 56.436347\n",
      "Error norm: 357.706217\n",
      "Active features: 4446\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Iteration #32 *****\n",
      "Loss: 6170.044083\n",
      "Feature norm: 58.178445\n",
      "Error norm: 411.844599\n",
      "Active features: 4217\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #33 *****\n",
      "Loss: 6105.850504\n",
      "Feature norm: 60.067281\n",
      "Error norm: 449.924844\n",
      "Active features: 4111\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #34 *****\n",
      "Loss: 6063.554950\n",
      "Feature norm: 60.951126\n",
      "Error norm: 140.069260\n",
      "Active features: 4084\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #35 *****\n",
      "Loss: 6023.252395\n",
      "Feature norm: 62.242327\n",
      "Error norm: 162.364541\n",
      "Active features: 3995\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #36 *****\n",
      "Loss: 5982.533256\n",
      "Feature norm: 63.136870\n",
      "Error norm: 149.182315\n",
      "Active features: 3847\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #37 *****\n",
      "Loss: 5952.692767\n",
      "Feature norm: 64.112695\n",
      "Error norm: 193.450850\n",
      "Active features: 3736\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #38 *****\n",
      "Loss: 5927.319340\n",
      "Feature norm: 64.775861\n",
      "Error norm: 161.163626\n",
      "Active features: 3657\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #39 *****\n",
      "Loss: 5903.170346\n",
      "Feature norm: 65.948146\n",
      "Error norm: 220.074868\n",
      "Active features: 3591\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #40 *****\n",
      "Loss: 5886.228432\n",
      "Feature norm: 66.590011\n",
      "Error norm: 80.325019\n",
      "Active features: 3525\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #41 *****\n",
      "Loss: 5868.930139\n",
      "Feature norm: 67.314112\n",
      "Error norm: 74.509518\n",
      "Active features: 3477\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #42 *****\n",
      "Loss: 5844.850925\n",
      "Feature norm: 68.487600\n",
      "Error norm: 174.728550\n",
      "Active features: 3400\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #43 *****\n",
      "Loss: 5830.795363\n",
      "Feature norm: 69.176759\n",
      "Error norm: 219.966141\n",
      "Active features: 3327\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #44 *****\n",
      "Loss: 5818.775635\n",
      "Feature norm: 69.581251\n",
      "Error norm: 101.177249\n",
      "Active features: 3273\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #45 *****\n",
      "Loss: 5806.365542\n",
      "Feature norm: 70.364255\n",
      "Error norm: 232.324357\n",
      "Active features: 3187\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #46 *****\n",
      "Loss: 5797.305043\n",
      "Feature norm: 70.738595\n",
      "Error norm: 191.993672\n",
      "Active features: 3127\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #47 *****\n",
      "Loss: 5789.381389\n",
      "Feature norm: 71.352041\n",
      "Error norm: 188.186995\n",
      "Active features: 3091\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #48 *****\n",
      "Loss: 5782.277003\n",
      "Feature norm: 71.528690\n",
      "Error norm: 72.811482\n",
      "Active features: 3065\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #49 *****\n",
      "Loss: 5774.694942\n",
      "Feature norm: 71.899587\n",
      "Error norm: 168.640634\n",
      "Active features: 3020\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Iteration #50 *****\n",
      "Loss: 5768.333054\n",
      "Feature norm: 72.084526\n",
      "Error norm: 151.404838\n",
      "Active features: 2983\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 1.054\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 2983 (32892)\n",
      "Number of active attributes: 2106 (29141)\n",
      "Number of active labels: 3 (3)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.006\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   B-Disease       0.86      0.71      0.78       960\n",
      "   I-Disease       0.85      0.75      0.79      1087\n",
      "           O       0.98      0.99      0.99     22450\n",
      "\n",
      "    accuracy                           0.97     24497\n",
      "   macro avg       0.90      0.82      0.85     24497\n",
      "weighted avg       0.97      0.97      0.97     24497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pycrfsuite\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train = [[extract_features(sent, i) for i in range(len(sent))] for sent in train_sentences]\n",
    "\n",
    "y_train = train_labels\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=True)\n",
    "for x, y in zip(X_train, y_train):\n",
    "    trainer.append(x, y)\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,\n",
    "    'c2': 1e-3,\n",
    "    'max_iterations': 50,\n",
    "    'feature.possible_transitions': True  \n",
    "})\n",
    "trainer.train('disease_model.crfsuite')\n",
    "\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('disease_model.crfsuite')\n",
    "\n",
    "\n",
    "# Create feature sequences for the test dataset\n",
    "X_test = [[extract_features(sent, i) for i in range(len(sent)) ] for sent in test_sentences]\n",
    "\n",
    "y_pred = [tagger.tag(x) for x in X_test]\n",
    "\n",
    "y_test_flat = [tag for labels in test_labels for tag in labels]\n",
    "y_pred_flat = [tag for tags in y_pred for tag in tags]\n",
    "\n",
    "report = classification_report(y_test_flat, y_pred_flat, labels=[\"B-Disease\", \"I-Disease\", \"O\"])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438bfa1d",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "\n",
    "In this problem you will examine parameter weights assigned by your model. You can do this by calling\n",
    "“tagger.info().transitions” and “tagger.info().state_features” on your trained model object.\n",
    "\n",
    "• In your notebook, show parameter weights given to transitions between the 3 tag types (\"B-\n",
    "Disease\",\"I-Disease\", and \"O\").\n",
    "\n",
    "• Refer back to the feature you designed in Problem 3 (the feature \"of your choice\"). Show the\n",
    "parameter weights assigned to this feature. You may truncate this list if it is very long. [This may\n",
    "happen if you included a word from the sequence in the feature name, so your feature was\n",
    "expanded to become a larger set of features that grows with your vocabulary]\n",
    "\n",
    "• *IF* your feature was dropped during model training (that is, there is nothing to show in the\n",
    "previous step) then return to Problem 4 and design a new feature that is used in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e5c7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition weights:\n",
      "Transition from O to O: 1.786906\n",
      "Transition from O to B-Disease: -0.303747\n",
      "Transition from O to I-Disease: -8.685557\n",
      "Transition from B-Disease to O: -1.761744\n",
      "Transition from B-Disease to B-Disease: -5.66115\n",
      "Transition from B-Disease to I-Disease: 1.625385\n",
      "Transition from I-Disease to O: -1.663512\n",
      "Transition from I-Disease to B-Disease: -4.065957\n",
      "Transition from I-Disease to I-Disease: 1.864707\n",
      "\n",
      "State feature weights (truncated):\n",
      "('w0.suffix3=ion', 'O'): 0.254854\n",
      "('w0.suffix3=ion', 'B-Disease'): -1.481054\n",
      "('w0.suffix3=ion', 'I-Disease'): 0.327464\n",
      "('w-1=BOS', 'O'): 4.200259\n",
      "('w-1=BOS', 'B-Disease'): 3.169447\n",
      "('w+1=of', 'O'): 0.888714\n",
      "('w+1=of', 'B-Disease'): 0.023472\n",
      "('w+1=of', 'I-Disease'): -1.535709\n",
      "('len=14', 'O'): -0.041638\n",
      "('len=14', 'B-Disease'): 0.234965\n",
      "('len=14', 'I-Disease'): -0.00441\n",
      "('w0.lower=of', 'O'): 1.028714\n",
      "('w0.lower=of', 'I-Disease'): 1.357102\n",
      "('w0.suffix3=of', 'O'): 1.012942\n",
      "('w0.suffix3=of', 'I-Disease'): 1.349851\n",
      "('len=2', 'O'): 1.005881\n",
      "('len=2', 'B-Disease'): -0.712558\n",
      "('len=2', 'I-Disease'): -0.517811\n",
      "('w-1=of', 'O'): -1.211602\n",
      "('w-1=of', 'B-Disease'): 0.341423\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "# Assuming you have trained your CRF model and have the 'tagger' object\n",
    "\n",
    "# Show parameter weights for transitions\n",
    "transitions = tagger.info().transitions\n",
    "print(\"Transition weights:\")\n",
    "for tag1, tag2 in transitions:\n",
    "    weight = transitions[(tag1, tag2)]\n",
    "    print(f\"Transition from {tag1} to {tag2}: {weight}\")\n",
    "\n",
    "# Show parameter weights for state features\n",
    "state_features = tagger.info().state_features\n",
    "print(\"\\nState feature weights (truncated):\")\n",
    "for feature, weight in list(state_features.items())[:20]:  # You can adjust the truncation as needed\n",
    "    print(f\"{feature}: {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018729c",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "\n",
    "Tag-level accuracy is easy to compute, but it is not very easy to understand. In particular, one disease\n",
    "reference may cover both \"B-Disease\" and \"I-Disease\" tokens. To give another view of model\n",
    "performance, compute document-level precision and recall on your experiment output. To do this:\n",
    "\n",
    "• Write a function that aggregates token-level tags to a document-level label. For example,\n",
    "convert a tag sequence like [\"O\", \"B-Disease\", \"I-Disease\", \"O\", \"O\"] to a single label y=1. Your\n",
    "function should assign y=1 to a sequence with one or more disease mentions (at least one \"B-\n",
    "Disease\" tag) and y=0 to a sequence with no disease mentions.\n",
    "\n",
    "• Apply your function to both true and predicted document-level labels from your test set. Use\n",
    "the output to compute document level precision and recall of your model. Show your results in\n",
    "your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a854eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document precision: 0.9730848861283644\n",
      "Document recall: 0.8719851576994434\n"
     ]
    }
   ],
   "source": [
    "def doc_labels(token_tags):\n",
    "    for tag in token_tags:\n",
    "        if tag in [\"B-Disease\", \"I-Disease\"]:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "y_test_docs = [doc_labels(ls) for ls in test_labels]\n",
    "y_pred_docs = [doc_labels(ls) for ls in y_pred]\n",
    "\n",
    "print(\"Document precision:\", precision_score(y_test_docs, y_pred_docs))  \n",
    "print(\"Document recall:\", recall_score(y_test_docs, y_pred_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb2b99b",
   "metadata": {},
   "source": [
    "# PROBLEM 7 \n",
    "\n",
    "State Transitions (10 pts – Answer in Blackboard)\n",
    "The python-crfsuite library allows you to set a Boolean hyper-parameter called\n",
    "“feature.possible_transitions”. If this parameter is True, then the model may output tag-to-tag\n",
    "transitions that were never seen in training data. [You do not need to apply this parameter in your code\n",
    "to answer this question]\n",
    "\n",
    "• What is an example of one tag-to-tag transition that never occurred in the training data?\n",
    "\n",
    "• For this particular experiment, do you think it makes sense to set this parameter to True or\n",
    "False? That is, should you allow transitions that never occurred in the training data? Explain your\n",
    "answer briefly."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f652b46",
   "metadata": {},
   "source": [
    "The \"feature.possible_transitions\" setting in crfsuite lets us control whether the model can predict tag transitions that were never seen in the training data.\n",
    "\n",
    "For example, say our training data doesn't show any direct transitions from a noun tag to a verb tag. The texts we trained on just don't contain those sequences. Well, if we turn on \"possible_transitions\", the model could suddenly start predicting noun-to-verb transitions even though it never saw them before.\n",
    "\n",
    "Whether to allow such unseen transitions really depends on our specific NLP task:\n",
    "\n",
    "If we enable them, it makes the model more flexible - it can handle new tag sequences and combinations, even rare ones not in the training data. This is good if our test data might contain fresh sequences.\n",
    "But it also introduces a risk - the model may start predicting very strange or incorrect sequences that never actually occur in your domain. \n",
    "If we disable possible transitions, the model sticks firmly to only things it saw during training. This prevents weird predictions but reduces flexibility. We have to weigh the pros and cons for our problem. If we expect our test data to match the training distribution, then disabling unseen transitions prevents unruly predictions. But if our task is open-ended, allowing them gives the model latitude to handle novel transitions.\n",
    "\n",
    "Lastly, we have to consider how representative our training data is, how structured our domain is, the risks of incorrect predictions, and how adaptive we need the model to be. The best setting depends on our specific goals and dataset characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83e631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
